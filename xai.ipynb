{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Sayfanın github reposuna buradan ulaşabilirsiniz \n",
    "[Github Linki](https://github.com/yalcinhayyam/xai)\n",
    "\n",
    "[XAI (Explainable AI)](#xai-explainable-ai)\n",
    "\n",
    "-   [SHAP](#shap)\n",
    "    1.  [Shap Nedir?](#shap-nedir)\n",
    "    2.  [Örnek](#örnek)\n",
    "-   [LIME](#lime)\n",
    "    1.  [Lime Nedir?](#lime-nedir)\n",
    "    2.  [Örnek](#c3b6rnek-1)\n",
    "-   [Shapash](#shapash)\n",
    "    1.  [Shapash Nedir?](#shapash-nedir)\n",
    "    2.  [Örnek](#c3b6rnek-2)\n",
    "-   [ELI5](#eli5)\n",
    "    1.  [ELI5 Nedir?](#eli5-nedir)\n",
    "    2.  [Örnek](#c3b6rnek-3)\n",
    "-   [InterpretML](#interpretml)\n",
    "    1.  [InterpretML Nedir?](#interpretml-nedir)\n",
    "    2.  [Örnek](#c3b6rnek-4)\n",
    "-   [OmniXAI](#omnixai)\n",
    "    1.  [OmniXAI Nedir?](#omnixai-nedir)\n",
    "    2.  [Örnek](#c3b6rnek-5)\n",
    "\n",
    "# XAI (Explainable AI)\n",
    "\n",
    "> Açıklanabilir AI (XAI), çözümün sonuçlarının insan uzmanlar tarafından\n",
    "> anlaşılabilmesi için yapay zeka teknolojisinin (AI) uygulanmasındaki\n",
    "> yöntem ve teknikleri ifade eder. Yapay zekanın neden belirli bir\n",
    "> karara vardığını tasarımcılarının bile açıklayamadığı makine\n",
    "> öğrenimindeki “kara kutu” kavramıyla çelişir.\n",
    "\n",
    "2 açıklanabilirlik yöntemi:\n",
    "\n",
    "-   Modele özgü (içsel): Modele özgü yorumlanabilirlik yöntemleri,\n",
    "    belirli model sınıflarıyla sınırlıdır. İçsel yöntemler, tanımı\n",
    "    gereği modele özgüdür.\n",
    "\n",
    "-   Modelden bağımsız (post-hoc): Modelden bağımsız yöntemler, belirli\n",
    "    bir makine öğrenimi modeline bağlı değildir. Modelden bağımsız\n",
    "    yorumlar genellikle post-hoc’tur.\n",
    "\n",
    "2 tür yorumlama:\n",
    "\n",
    "-   Yerel: Belirli bir tahminin nasıl ve neden yapıldığını açıklayın\n",
    "\n",
    "-   Global: Bir modelin genel olarak nasıl çalıştığını açıklayın\n",
    "    Modelinizin ortalama olarak neyi önemsediği ve bunların sonucu nasıl\n",
    "    etkilediği\n",
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fa838",
   "metadata": {},
   "source": [
    "\n",
    "## SHAP\n",
    "\n",
    "### Shap Nedir?\n",
    "\n",
    "SHAP (SHapley Additive ExPlanations), herhangi bir makine öğrenimi\n",
    "modelinin çıktısını açıklamaya yönelik oyun kuramsal bir yaklaşımdır.\n",
    "Oyun teorisindeki klasik Shapley değerlerini ve bunların ilgili\n",
    "uzantılarını kullanan yerel açıklamalarla optimum kredi tahsisini\n",
    "birleştirir.\n",
    "\n",
    "SHAP’ ı kurmak için, terminalde bu kodları çalıştırmamız yeterlidir\n",
    "\n",
    "``` bash\n",
    "!pip install shap\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640a60f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24737ead",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![BeeSwarm](./images/shap_beeswarm.png)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı\n",
    "\\>](https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/plots/beeswarm.html)\n",
    "\n",
    "[Başka bir örnek \n",
    "\\>](https://colab.research.google.com/github/kweinmeister/notebooks/blob/master/tensorflow-shap-college-debt.ipynb)\n",
    "\n",
    "Klasik UCI yetişkin geliri veri kümesi üzerinde eğitilmiş bir XGBoost\n",
    "modeli kullanır (bu, insanların 1990’larda 50.000 doların üzerinde\n",
    "kazanıp kazanmadığını tahmin etmek için bir sınıflandırma görevidir).\n",
    "\n",
    "Beeswarm çizimi, bir veri kümesindeki en önemli özelliklerin modelin\n",
    "çıktısını nasıl etkilediğine dair bilgi açısından yoğun bir özet\n",
    "görüntülemek için tasarlanmıştır. Verilen açıklamanın her örneği, her\n",
    "özellik akışında tek bir nokta ile temsil edilir. Noktanın x konumu, o\n",
    "özelliğin SHAP değeri (shap_values.value\\[instance,feature\\]) tarafından\n",
    "belirlenir ve noktalar, yoğunluğu göstermek için her bir özellik satırı\n",
    "boyunca “yığılır”. Renk, bir özelliğin orijinal değerini görüntülemek\n",
    "için kullanılır (shap_values.data\\[örnek,özellik\\]). Aşağıdaki çizimde,\n",
    "Yaşın ortalama olarak en önemli özellik olduğunu ve genç (mavi)\n",
    "insanların 50.000 doları aşma olasılığının daha düşük olduğunu\n",
    "görebiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed921f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install xgboost "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1300d0f7",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "# shap.plots.beeswarm\n",
    "import xgboost\n",
    "import shap\n",
    "\n",
    "# train XGBoost model\n",
    "X,y = shap.datasets.adult()\n",
    "model = xgboost.XGBClassifier().fit(X, y)\n",
    "\n",
    "# compute SHAP values\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "```\n",
    "\n",
    "``` py\n",
    "shap.plots.beeswarm(shap_values)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shap.plots.beeswarm\n",
    "import xgboost\n",
    "import shap\n",
    "\n",
    "# train XGBoost model\n",
    "X,y = shap.datasets.adult()\n",
    "model = xgboost.XGBClassifier().fit(X, y)\n",
    "\n",
    "# compute SHAP values\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69170a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4fda2bb",
   "metadata": {},
   "source": [
    "\n",
    "## LIME\n",
    "\n",
    "### Lime Nedir?\n",
    "\n",
    "LIME kısaltması, Yerel Yorumlanabilir Model-agnostik Açıklamalar\n",
    "anlamına gelir. Proje, makine öğrenimi modellerinin ne yaptığını\n",
    "açıklamakla ilgilidir (kaynak). LIME tablo modelleri, metin\n",
    "sınıflandırıcılar ve görüntü sınıflandırıcılar (şu anda) için\n",
    "açıklamaları destekler.\n",
    "\n",
    "Lime’ ı kurmak için, terminalde bu kodları çalıştırmamız yeterlidir\n",
    "\n",
    "``` bash\n",
    "pip install lime\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa0765",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install lime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3fffb6d",
   "metadata": {},
   "source": [
    "\n",
    "![Lime](./images/lime.webp)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı\n",
    "\\>](https://towardsdatascience.com/lime-how-to-interpret-machine-learning-models-with-python-94b0e7e4432e)\n",
    "\n",
    "[Şarap Kalitesi Data Seti\n",
    "\\>](https://www.kaggle.com/datasets/piyushagni5/white-wine-quality)\n",
    "\n",
    "Bir modeli eğitmeden önce yorumlayamazsınız, bu yüzden ilk adım budur.\n",
    "Şarap kalitesi veri setinin eğitilmesi kolaydır ve bir dizi\n",
    "yorumlanabilir özellikle birlikte gelir. Python’a nasıl yükleyeceğiniz\n",
    "aşağıda açıklanmıştır\n",
    "\n",
    "``` py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('wine.csv')\n",
    "wine.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('data/lime/wine.csv')\n",
    "wine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41e80469",
   "metadata": {},
   "source": [
    "\n",
    "Tüm nitelikler sayısaldır ve eksik değer yoktur, bu nedenle listeden\n",
    "çapraz veri hazırlığı yapabilirsiniz.\n",
    "\n",
    "Eğitim/Test ayrımı bir sonraki adımdır. Sütun kalitesi, olası iyi ve\n",
    "kötü değerleri ile hedef değişkendir. Aynı bölünmeyi elde etmek\n",
    "istiyorsanız, random_state parametresini 42 olarak ayarlayalım.\n",
    "\n",
    "``` py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wine.drop('quality', axis=1)\n",
    "y = wine['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wine.drop('quality', axis=1)\n",
    "y = wine['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f324063",
   "metadata": {},
   "source": [
    "\n",
    "Geriye kalan tek şey maket eğitimi. ScikitLearn’den\n",
    "RandomForestClassifier bu işi yapacak ve onu eğitim setine sığdırmanız\n",
    "gerekecek. Kutudan çıkar çıkmaz %80 doğruluğa sahip bir sınıflandırıcı\n",
    "alacaksınız (score)\n",
    "\n",
    "``` py\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47876cd5",
   "metadata": {},
   "source": [
    "\n",
    "#### Model interpretation\n",
    "\n",
    "Modeli açıklamaya başlamak için önce LIME kitaplığını içe aktarmanız ve\n",
    "tablo şeklinde bir açıklayıcı nesne oluşturmanız gerekir. Aşağıdaki\n",
    "parametreleri bekler\n",
    "\n",
    "-   training_data – eğitim/test bölümüyle oluşturulan eğitim\n",
    "    verilerimiz. Numpy dizi biçiminde olmalıdır.\n",
    "-   feature_names – eğitim kümesindeki sütun adları\n",
    "-   class_names – hedef değişkenden farklı sınıflar\n",
    "-   mode – çözdüğünüz problemin türü (bu durumda sınıflandırma)\n",
    "\n",
    "Here’s the code\n",
    "\n",
    "``` py\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['bad', 'good'],\n",
    "    mode='classification'\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['bad', 'good'],\n",
    "    mode='classification'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6c5530f",
   "metadata": {},
   "source": [
    "\n",
    "İşte bu kadar\n",
    "\n",
    "-   yorumlamaya başlayabilirsiniz! Önce kötü bir şarap gelir. Test\n",
    "    setinin ikinci satırı, kötü olarak sınıflandırılan şarabı temsil\n",
    "    eder. Tahmini açıklamak için açıklayıcı nesnenin açıklayıcı örnek\n",
    "    işlevini çağırabilirsiniz. Aşağıdaki parametreler gereklidir:\n",
    "\n",
    "-   data_row - veri kümesinden tek bir gözlem\n",
    "\n",
    "-   predict_fn – tahmin yapmak için kullanılan bir işlev. Modelden\n",
    "    predict_proba, olasılıkları gösterdiği için harika bir seçenektir.\n",
    "\n",
    "İşte kod\n",
    "\n",
    "``` py\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test.iloc[1],\n",
    "    predict_fn=model.predict_proba\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test.iloc[1],\n",
    "    predict_fn=model.predict_proba\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85387880",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "exp.show_in_notebook(show_table=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10de41",
   "metadata": {},
   "source": [
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0295d540",
   "metadata": {},
   "source": [
    "\n",
    "## Shapash\n",
    "\n",
    "### Shapash Nedir?\n",
    "\n",
    "Shapash, makine öğrenimini herkes tarafından yorumlanabilir ve anlaşılır\n",
    "hale getirmeyi amaçlayan bir Python kitaplığıdır. Herkesin\n",
    "anlayabileceği açık etiketleri görüntüleyen çeşitli görselleştirme\n",
    "türleri sağlar.\n",
    "\n",
    "Shapash’ ı kurmak için, terminalde bu kodları çalıştırmamız yeterlidir\n",
    "\n",
    "``` bash\n",
    "pip install shapash\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39638a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install shapash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f41512",
   "metadata": {},
   "source": [
    "\n",
    "![shapash](./images/shapash.png)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı\n",
    "\\>](https://shapash.readthedocs.io/en/latest/tutorials/tutorial02-Shapash-overview-in-Jupyter.html)\n",
    "\n",
    "[Ev Fiyatları Data Seti\n",
    "\\>](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "``` py\n",
    "import pandas as pd\n",
    "from category_encoders import OrdinalEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import OrdinalEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50b23ac0",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "from shapash.data.data_loader import data_loading\n",
    "house_df, house_dict = data_loading('house_prices')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash.data.data_loader import data_loading\n",
    "house_df, house_dict = data_loading('house_prices')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e922ca81",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "y_df=house_df['SalePrice'].to_frame()\n",
    "X_df=house_df[house_df.columns.difference(['SalePrice'])]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df=house_df['SalePrice'].to_frame()\n",
    "X_df=house_df[house_df.columns.difference(['SalePrice'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de94f0b2",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "house_df.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8abac598",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "categorical_features = [col for col in X_df.columns if X_df[col].dtype == 'object']\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    cols=categorical_features,\n",
    "    handle_unknown='ignore',\n",
    "    return_df=True).fit(X_df)\n",
    "\n",
    "X_df=encoder.transform(X_df)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "categorical_features = [col for col in X_df.columns if X_df[col].dtype == 'object']\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    cols=categorical_features,\n",
    "    handle_unknown='ignore',\n",
    "    return_df=True).fit(X_df)\n",
    "\n",
    "X_df=encoder.transform(X_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da57b320",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_df, y_df, train_size=0.75, random_state=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee22c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_df, y_df, train_size=0.75, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c65246e",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "regressor = LGBMRegressor(n_estimators=200).fit(Xtrain,ytrain)\n",
    "y_pred = pd.DataFrame(regressor.predict(Xtest),columns=['pred'],index=Xtest.index)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LGBMRegressor(n_estimators=200).fit(Xtrain,ytrain)\n",
    "y_pred = pd.DataFrame(regressor.predict(Xtest),columns=['pred'],index=Xtest.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2915df1c",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "from shapash import SmartExplainer\n",
    "\n",
    "xpl = SmartExplainer(\n",
    "    model=regressor,\n",
    "    preprocessing=encoder, # Optional: compile step can use inverse_transform method\n",
    "    features_dict=house_dict  # Optional parameter, dict specifies label for features name\n",
    ")\n",
    "\n",
    "xpl.compile(x=Xtest,\n",
    " y_pred=y_pred,\n",
    " y_target=ytest, # Optional: allows to display True Values vs Predicted Values\n",
    " )\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38497a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapash import SmartExplainer\n",
    "\n",
    "xpl = SmartExplainer(\n",
    "    model=regressor,\n",
    "    preprocessing=encoder, # Optional: compile step can use inverse_transform method\n",
    "    features_dict=house_dict  # Optional parameter, dict specifies label for features name\n",
    ")\n",
    "\n",
    "xpl.compile(x=Xtest,\n",
    " y_pred=y_pred,\n",
    " y_target=ytest, # Optional: allows to display True Values vs Predicted Values\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a5f1511",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "xpl.plot.features_importance()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpl.plot.features_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01460ed2",
   "metadata": {},
   "source": [
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aba88a5d",
   "metadata": {},
   "source": [
    "\n",
    "## ELI5\n",
    "\n",
    "### ELI5 Nedir?\n",
    "\n",
    "ELI5, çeşitli Makine Öğrenimi modellerini görselleştirmek ve hata\n",
    "ayıklamak için tek tip bir API kullanan bir Python araç setidir. Tüm\n",
    "scikit-learn algoritmalarını destekler (fit() ve predict() yöntemleri\n",
    "dahil). Çok sayıda makine öğrenimi çerçevesi için yerleşik destek içerir\n",
    "ve beyaz kutu modellerini (Doğrusal Regresyon, Karar Ağaçları) ve kara\n",
    "kutu modellerini (Keras, XGBoost, LightGBM) açıklamanıza olanak tanır.\n",
    "Hem regresyon hem de sınıflandırma modellerine uygulanabilir.\n",
    "\n",
    "ELI5’ ı kurmak için, terminalde bu kodları çalıştırmamız yeterlidir\n",
    "\n",
    "``` bash\n",
    "!pip install eli5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689e252",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install eli5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7367e3e",
   "metadata": {},
   "source": [
    "![ELI5](./images/eli5.png)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı\n",
    "\\>](https://analyticsindiamag.com/how-to-visualize-and-debug-machine-learning-models-using-eli5/)\n",
    "\n",
    "``` py\n",
    "from xgboost import XGBClassifier\n",
    "import eli5\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "import eli5\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37ac4cc9",
   "metadata": {},
   "source": [
    "\n",
    "> Burada kullandığımız veri seti, uygularken göğüs kanseri tahmini için\n",
    "> yerleşik sklearn veri setidir. Uygun başlık ile meme kanseri veri seti\n",
    "> için bir pandas veri çerçevesi oluşturun, bunun nedeni, eli5’i\n",
    "> çalıştırdığımızda, özellik bilgilerini modelden almasıdır.\n",
    "\n",
    "``` py\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data)\n",
    "df.columns = data.feature_names\n",
    "df['target'] = data.target\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data)\n",
    "df.columns = data.feature_names\n",
    "df['target'] = data.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88e44b7c",
   "metadata": {},
   "source": [
    "\n",
    "Bir sınıflandırıcı oluşturalım\n",
    "\n",
    "``` py\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493571c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88d6d595",
   "metadata": {},
   "source": [
    "\n",
    "Şimdi aşağıdaki gibi ELI5’in sadece iki basit işlevsel API’sini\n",
    "kullanmamız gerekiyor.\n",
    "\n",
    "``` py\n",
    "eli5.show_weights(model, top=30)\n",
    "eli5.explain_prediction_xgboost(model,x_test.iloc[0])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(model, top=30)\n",
    "eli5.explain_prediction_xgboost(model,x_test.iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfbb837e",
   "metadata": {},
   "source": [
    "\n",
    "> Sol taraf, her özellik için atanan ağırlıkları gösterir ve sağ taraf,\n",
    "> bir örnek için tahmini gösterir.\n",
    "\n",
    "> Yukarıdaki iki tablodan görebileceğiniz gibi, XGBoost’un eğitim\n",
    "> verilerine dayalı olarak her özellik için nasıl ağırlık atadığını ve\n",
    "> diğer tablodan, belirli bir örnek için, her bir özelliğin nasıl\n",
    "> katkıda bulunduğu sınıf 1 için 0,981 olasılığa ulaşmak için nasıl\n",
    "> atadığını görebileceğiniz gibi.\n",
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f8ccc50",
   "metadata": {},
   "source": [
    "\n",
    "## InterpretML\n",
    "\n",
    "### InterpretML Nedir?\n",
    "\n",
    "InterpretML, en yeni makine öğrenimi yorumlanabilirlik tekniklerini tek\n",
    "bir çatı altında birleştiren açık kaynaklı bir pakettir. Bu paket ile\n",
    "yorumlanabilir cam kutu modelleri eğitebilir ve kara kutu sistemlerini\n",
    "anlatabilirsiniz. InterpretML, modelinizin genel davranışını veya\n",
    "bireysel tahminlerin arkasındaki nedenleri anlamanıza yardımcı olur.\n",
    "\n",
    "InterpretML’ ı kurmak için, terminalde bu kodları çalıştırmamız\n",
    "yeterlidir\n",
    "\n",
    "``` bash\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac37912",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install interpret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13caae24",
   "metadata": {},
   "source": [
    "\n",
    "![InterpretML](./images/interpetML.png)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı \\>](https://github.com/interpretml/interpret)\n",
    "\n",
    "[Jupyter Dökümanı\n",
    "\\>](https://nbviewer.org/github/interpretml/interpret/blob/master/benchmarks/EBM%20Classification%20Comparison.ipynb)\n",
    "\n",
    "[Yetişkin Listesi Data Seti\n",
    "\\>](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/)\n",
    "\n",
    "Klasik UCI yetişkin geliri veri kümesi üzerinde eğitilmiş bir XGBoost\n",
    "modeli kullanır (bu, insanların 1990’larda 50.000 doların üzerinde\n",
    "kazanıp kazanmadığını tahmin etmek için bir sınıflandırma görevidir).\n",
    "\n",
    "InterpretML, bir veri kümesindeki en önemli özelliklerin modelin\n",
    "çıktısını nasıl etkilediğine dair yoğun bilgi içeren bir özet\n",
    "görüntülemek üzere tasarlanmıştır. Aşağıdaki çizimde, Yaşın ortalama\n",
    "olarak en önemli özellik olduğunu ve gençlerin 50.000 doları aşma\n",
    "olasılığının daha düşük olduğunu görebiliriz.\n",
    "\n",
    "``` py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    header=None)\n",
    "df.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "# df = df.sample(frac=0.1, random_state=1)\n",
    "train_cols = df.columns[0:-1]\n",
    "label = df.columns[-1]\n",
    "X = df[train_cols]\n",
    "y = df[label].apply(lambda x: 0 if x == \" <=50K\" else 1) #Turning response into 0 and 1\n",
    "\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    header=None)\n",
    "df.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "# df = df.sample(frac=0.1, random_state=1)\n",
    "train_cols = df.columns[0:-1]\n",
    "label = df.columns[-1]\n",
    "X = df[train_cols]\n",
    "y = df[label].apply(lambda x: 0 if x == \" <=50K\" else 1) #Turning response into 0 and 1\n",
    "\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78fc01e5",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "from interpret import show\n",
    "from interpret.data import ClassHistogram\n",
    "\n",
    "hist = ClassHistogram().explain_data(X_train, y_train, name = 'Train Data')\n",
    "show(hist)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831315d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "from interpret.data import ClassHistogram\n",
    "\n",
    "hist = ClassHistogram().explain_data(X_train, y_train, name = 'Train Data')\n",
    "show(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9572b0",
   "metadata": {},
   "source": [
    "\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c53a600e",
   "metadata": {},
   "source": [
    "\n",
    "## OmniXAI\n",
    "\n",
    "### OmniXAI Nedir?\n",
    "\n",
    "OmniXAI (Omni eXplainable AI’nin kısaltması), pratikte makine öğrenimi\n",
    "modelleri tarafından alınan kararları açıklamada birçok sıkıntılı\n",
    "noktayı ele almak için çok yönlü açıklanabilir yapay zeka ve\n",
    "yorumlanabilir makine öğrenimi yetenekleri sunan, açıklanabilir yapay\n",
    "zeka (XAI) için bir Python makine öğrenimi kitaplığıdır. OmniXAI, ML\n",
    "sürecinin farklı aşamalarında çeşitli veri türleri, modeller ve açıklama\n",
    "yöntemleri için açıklamaya ihtiyaç duyan veri bilimcileri, ML\n",
    "araştırmacıları ve uygulayıcılar için açıklanabilir yapay zekayı\n",
    "kolaylaştıran tek noktadan kapsamlı bir kitaplık olmayı amaçlamaktadır:\n",
    "\n",
    "``` bash\n",
    "pip install omnixai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1947b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install omnixai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4a59f00",
   "metadata": {},
   "source": [
    "\n",
    "![OmniXAI-LIME](./images/omnixai.png)\n",
    "\n",
    "### Örnek\n",
    "\n",
    "[Tam Örnek Dökümanı \\>](https://github.com/salesforce/OmniXAI)\n",
    "\n",
    "[Yetişkin Listesi Data Seti\n",
    "\\>](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/)\n",
    "\n",
    "Örnek olarak gelir tahmini görevini ele alalım. Bu örnekte kullanılan\n",
    "veri seti, gelir tahmini içindir. Tablolu bir veri kümesini temsil etmek\n",
    "için Tabular veri sınıfını kullanmanızı öneririz. Pandas veri çerçevesi\n",
    "verilen bir Tabular örneği oluşturmak için veri çerçevesini, kategorik\n",
    "özellik adlarını (varsa) ve hedef/etiket sütun adını (varsa) belirtmeniz\n",
    "gerekir.\n",
    "\n",
    "[Omnixai Tabular\n",
    "Örneği\\>](https://github.com/salesforce/OmniXAI/blob/main/tutorials/tabular_classification.ipynb)\n",
    "\n",
    "``` py\n",
    "# This default renderer is used for sphinx docs only. Please delete this cell in IPython.\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This default renderer is used for sphinx docs only. Please delete this cell in IPython.\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8800ffc",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from omnixai.explainers.tabular import TabularExplainer\n",
    "from omnixai.visualization.dashboard import Dashboard\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from omnixai.data.tabular import Tabular\n",
    "from omnixai.preprocessing.tabular import TabularTransform\n",
    "from omnixai.explainers.tabular import TabularExplainer\n",
    "from omnixai.visualization.dashboard import Dashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34ed597e",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "# Load the dataset\n",
    "feature_names = [\n",
    "    \"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "    \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "    \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "    \"Capital Loss\", \"Hours per week\", \"Country\", \"label\"\n",
    "]\n",
    "df = pd.DataFrame(\n",
    "    np.genfromtxt(os.path.join('data', 'adult.data'), delimiter=', ', dtype=str),\n",
    "    columns=feature_names\n",
    ")\n",
    "tabular_data = Tabular(\n",
    "    data=df,\n",
    "    categorical_columns=[feature_names[i] for i in [1, 3, 5, 6, 7, 8, 9, 13]],\n",
    "    target_column='label'\n",
    ")\n",
    "print(tabular_data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2036d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "feature_names = [\n",
    "    \"Age\", \"Workclass\", \"fnlwgt\", \"Education\",\n",
    "    \"Education-Num\", \"Marital Status\", \"Occupation\",\n",
    "    \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\",\n",
    "    \"Capital Loss\", \"Hours per week\", \"Country\", \"label\"\n",
    "]\n",
    "df = pd.DataFrame(\n",
    "    np.genfromtxt(os.path.join('data', 'adult.data'), delimiter=', ', dtype=str),\n",
    "    columns=feature_names\n",
    ")\n",
    "tabular_data = Tabular(\n",
    "    data=df,\n",
    "    categorical_columns=[feature_names[i] for i in [1, 3, 5, 6, 7, 8, 9, 13]],\n",
    "    target_column='label'\n",
    ")\n",
    "print(tabular_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a191351c",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "# Train an XGBoost model\n",
    "np.random.seed(1)\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "train, test, train_labels, test_labels = \\\n",
    "    sklearn.model_selection.train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
    "print('Training data shape: {}'.format(train.shape))\n",
    "print('Test data shape:     {}'.format(test.shape))\n",
    "\n",
    "gbtree = xgboost.XGBClassifier(n_estimators=300, max_depth=5)\n",
    "gbtree.fit(train, train_labels)\n",
    "print('Test accuracy: {}'.format(\n",
    "    sklearn.metrics.accuracy_score(test_labels, gbtree.predict(test))))\n",
    "\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5285566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an XGBoost model\n",
    "np.random.seed(1)\n",
    "transformer = TabularTransform().fit(tabular_data)\n",
    "class_names = transformer.class_names\n",
    "x = transformer.transform(tabular_data)\n",
    "train, test, train_labels, test_labels = \\\n",
    "    sklearn.model_selection.train_test_split(x[:, :-1], x[:, -1], train_size=0.80)\n",
    "print('Training data shape: {}'.format(train.shape))\n",
    "print('Test data shape:     {}'.format(test.shape))\n",
    "\n",
    "gbtree = xgboost.XGBClassifier(n_estimators=300, max_depth=5)\n",
    "gbtree.fit(train, train_labels)\n",
    "print('Test accuracy: {}'.format(\n",
    "    sklearn.metrics.accuracy_score(test_labels, gbtree.predict(test))))\n",
    "\n",
    "# Convert the transformed data back to Tabular instances\n",
    "train_data = transformer.invert(train)\n",
    "test_data = transformer.invert(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77836760",
   "metadata": {},
   "source": [
    "\n",
    "> TabularExplainer’ı başlatmak için aşağıdaki parametreleri ayarlamamız\n",
    "> gerekir:\n",
    "\n",
    "> -   explainers: Uygulanacak açıklayıcıların adları, örneğin, \\[“lime”,\n",
    ">     “shap”, “mace”, “pdp”\\].\n",
    "\n",
    "> -   data: Açıklayıcıları başlatmak için kullanılan veriler. data,\n",
    ">     makine öğrenimi modelini eğitmek için eğitim veri kümesidir.\n",
    ">     Eğitim veri kümesi çok büyükse,\n",
    ">     omnixai.sampler.tabular.Sampler.subsample uygulanarak veriler\n",
    ">     bunun bir alt kümesi olabilir.\n",
    "\n",
    "> -   model: Açıklanacak makine öğrenimi modeli, örneğin bir\n",
    ">     scikit-learn modeli, bir tensorflow modeli, bir pytorch modeli\n",
    ">     veya bir kara kutu tahmin işlevi.\n",
    "\n",
    "> -   preprocess: Ham verileri (Tablo örneği) modelin girdilerine\n",
    ">     dönüştüren önişleme işlevi. son işlem (isteğe bağlı): Modelin\n",
    ">     çıktılarını kullanıcıya özel bir forma, örneğin her sınıf için\n",
    ">     tahmin edilen olasılığa dönüştüren son işleme işlevi. Son işlemin\n",
    ">     çıktısı bir numpy dizisi olmalıdır.\n",
    "\n",
    "> -   mode: Görev türü, ör. “sınıflandırma” veya “gerileme”. Ön işleme\n",
    ">     işlevi, girdi olarak bir Tabular örneğini alır ve makine öğrenimi\n",
    ">     modelinin tükettiği işlenmiş özelliklerin çıktısını verir. Bu\n",
    ">     örnekte, basitçe transformator.transform diyoruz. Panda veri\n",
    ">     çerçevelerinde bazı özel dönüşümler kullanılıyorsa, önişleme\n",
    ">     işlevi şu türde bir biçime sahiptir: lambda z:\n",
    ">     some_transform(z.to_pd()).\n",
    "\n",
    "``` py\n",
    "preprocess = lambda z: transformer.transform(z)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = lambda z: transformer.transform(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e689e5f",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "# Initialize a TabularExplainer\n",
    "explainers = TabularExplainer(\n",
    "    explainers=[\"lime\", \"shap\", \"mace\", \"pdp\", \"ale\"],\n",
    "    mode=\"classification\",\n",
    "    data=train_data,\n",
    "    model=gbtree,\n",
    "    preprocess=preprocess,\n",
    "    params={\n",
    "        \"lime\": {\"kernel_width\": 3},\n",
    "        \"shap\": {\"nsamples\": 100},\n",
    "        \"mace\": {\"ignored_features\": [\"Sex\", \"Race\", \"Relationship\", \"Capital Loss\"]}\n",
    "    }\n",
    ")\n",
    "# Generate explanations\n",
    "test_instances = test_data[1653:1658]\n",
    "local_explanations = explainers.explain(X=test_instances)\n",
    "global_explanations = explainers.explain_global(\n",
    "    params={\"pdp\": {\"features\": [\"Age\", \"Education-Num\", \"Capital Gain\",\n",
    "                                 \"Capital Loss\", \"Hours per week\", \"Education\",\n",
    "                                 \"Marital Status\", \"Occupation\"]}}\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b999aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TabularExplainer\n",
    "explainers = TabularExplainer(\n",
    "    explainers=[\"lime\", \"shap\", \"mace\", \"pdp\", \"ale\"],\n",
    "    mode=\"classification\",\n",
    "    data=train_data,\n",
    "    model=gbtree,\n",
    "    preprocess=preprocess,\n",
    "    params={\n",
    "        \"lime\": {\"kernel_width\": 3},\n",
    "        \"shap\": {\"nsamples\": 100},\n",
    "        \"mace\": {\"ignored_features\": [\"Sex\", \"Race\", \"Relationship\", \"Capital Loss\"]}\n",
    "    }\n",
    ")\n",
    "# Generate explanations\n",
    "test_instances = test_data[1653:1658]\n",
    "local_explanations = explainers.explain(X=test_instances)\n",
    "global_explanations = explainers.explain_global(\n",
    "    params={\"pdp\": {\"features\": [\"Age\", \"Education-Num\", \"Capital Gain\",\n",
    "                                 \"Capital Loss\", \"Hours per week\", \"Education\",\n",
    "                                 \"Marital Status\", \"Occupation\"]}}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e3a15c",
   "metadata": {},
   "source": [
    "\n",
    "``` py\n",
    "index=1\n",
    "print(\"LIME results:\")\n",
    "local_explanations[\"lime\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"SHAP results:\")\n",
    "local_explanations[\"shap\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"MACE results:\")\n",
    "local_explanations[\"mace\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"PDP results:\")\n",
    "global_explanations[\"pdp\"].ipython_plot(class_names=class_names)\n",
    "print(\"ALE results:\")\n",
    "global_explanations[\"ale\"].ipython_plot(class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=1\n",
    "print(\"LIME results:\")\n",
    "local_explanations[\"lime\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"SHAP results:\")\n",
    "local_explanations[\"shap\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"MACE results:\")\n",
    "local_explanations[\"mace\"].ipython_plot(index, class_names=class_names)\n",
    "print(\"PDP results:\")\n",
    "global_explanations[\"pdp\"].ipython_plot(class_names=class_names)\n",
    "print(\"ALE results:\")\n",
    "global_explanations[\"ale\"].ipython_plot(class_names=class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa7c45c839627294820c8aab8d3cd0a09764bbbc9a7bfd18a53aac1d4143147e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
